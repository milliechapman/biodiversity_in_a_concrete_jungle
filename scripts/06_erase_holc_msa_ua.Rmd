---
title: "06_erase_holc_msa"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---

This does a lot of one-time work. No need to re-run


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 0 set up: load libraries, custom functions, set defaults
```{r}

# load libraries
# packages we'll be using
packs <- c(
    'tidyverse'  # a must have
  , 'tidylog'    # prints out what was done in dplyr and tidr
  # , 'gbifdb' # GBIF
  , 'fst' # a faster table, makes outputs files much smaller, too.
  # , 'terra'
  # , 'KnowBR'    # creates biodiversity estimates like completeness.
  , 'tidycensus'      # Census access
  , 'sf'        # spatial support
  , 'mapview'   # webmaps
  , 'janitor'   # cleans things up, also pipe-friendly cross-tabulations
  , 'tictoc'    # times things
  , 'beepr'     # makes noises
)


# check for all of the libraries, install if you don't have them
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# load them
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)



# set custom function for getting spatial data
see_sf <- function(){
# what's in memory that are sf - spatial features?
keep(eapply(.GlobalEnv, class),      # gets the objects in the global environment
     ~ any(str_detect(., "sf"))) %>% # selects elements with sf in them
    names(.) %>% as.character(.)     # my simple features
}

see_sf() -> sf_in_memory

# what are the spatial references of those SF classes?
mget(sf_in_memory) %>% purrr::map(~st_crs(.x)$epsg) %>% unlist() #%>% View()


# # get file size
# for(obj in ls()){message(obj); print(object.size(get(obj)), units='auto'); cat('\n')}; rm(obj)

# thanks Phil Donovan @philip_donovan
# https://www.spatialanalytics.co.nz/post/2018/04/01/fixing-st-par/
# Paralise any simple features analysis.
st_parallel <- function(sf_df, sf_func, n_cores, ...){

  # Create a vector to split the data set up by.
  split_vector <- rep(1:n_cores, each = nrow(sf_df) / n_cores, length.out = nrow(sf_df))

  # Perform GIS analysis
  split_results <- split(sf_df, split_vector) %>%
    parallel::mclapply(function(x) sf_func(x, ...), mc.cores = n_cores)


  # Define the output_class. If length is greater than two, then grab the second variable.
  output_class <- class(split_results[[1]])
  if (length(output_class) == 2){
    output_class <- output_class[2]
  }

  # Combine results back together. Method of combining depends on the output from the function.
  if (output_class == "matrix"){
    result <- do.call("rbind", split_results)
    names(result) <- NULL
  } else if (output_class == "sfc") {
    result <- do.call("c", split_results)
    result <- sf_func(result) # do.call combines the list but there are still n_cores of the geometry which had been split up. Running st_union or st_collect gathers them up into one, as is the expected output of these two functions.
  } else if (output_class %in% c('list', 'sgbp') ){
    result <- do.call("c", split_results)
    names(result) <- NULL
  } else if (output_class == "data.frame" ){
    result <- do.call("rbind", split_results)
  } else {
    stop("Unknown class. st_parallel only accepts the following outputs at present: sfc, list, sf, matrix, sgbp.")
  }

  # Return result
  return(result)
}


# Paralise any simple features analysis.
# https://www.spatialanalytics.co.nz/post/2017/09/11/a-parallel-function-for-spatial-analysis-in-r/
# define
st_par <- function(sf_df, sf_func, n_cores, ...){
  # Create a vector to split the data set up by.
  split_vector <- rep(1:n_cores, each = nrow(sf_df) / n_cores, length.out = nrow(sf_df))
  
  # Perform GIS analysis
  split_results <- split(sf_df, split_vector) %>%
    parallel::mclapply(function(x) sf_func(x, ...), mc.cores = n_cores)
  
  # Combine results back together. Method of combining depends on the output from the function.
  if (class(split_results[[1]]) == 'list' ){
    result <- do.call("c", split_results)
    names(result) <- NULL
    } else {
      result <- do.call("rbind", split_results)
      }
  # Return result
  return(result)
  }



# make donut function
st_erase <- function(x, y) st_difference(x, st_union(st_combine(y)))


# erase that handles geometries more smoothly ()
# via @tiennebr https://github.com/r-spatial/sf/issues/1280
st_erase_2 = function(x, y) {
    st_difference(
        st_geometry(x) %>% st_buffer(0), 
        st_union(st_combine(st_geometry(y))) %>% st_buffer(0)
    )
}


st_erase_3 = function(x, y) {
    st_difference(
        x %>% st_buffer(0), 
        st_union(st_combine(st_geometry(y))) %>% st_buffer(0))
}


# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


# redlining colors
holc_pal <- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              #, '#A9A9A9'
              ) # dark gray)

holc_pal_f<- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              , '#A9A9A9'
              , '#000000')

# fixes mapview
mapviewOptions(fgb = FALSE)

sf::sf_use_s2(FALSE) # supresses error in some sf operations


# data(adworld) # needed for KnowBPolygon
```


# 1 read in spatial data
## A HOLC
```{r}

# sf::sf_use_s2(FALSE) # supresses error about invalid loops in 1212, 2851
# # https://stackoverflow.com/questions/68478179/how-to-resolve-spherical-geometry-failures-when-joining-spatial-data
# 
# tic(); (holc <- 
#           st_read("https://dsl.richmond.edu/panorama/redlining/static/fullDownload.geojson") |> 
#           # st_read('input_data/HOLC_shapefile/holc_ad_data.shp', as_tibble = TRUE) |> 
#           filter(!is.na(holc_grade) & holc_grade != 'E') %>%
#           st_cast('POLYGON') %>% # IMPORTANT
#           filter(!st_is_empty(.)) %>% 
#           st_make_valid(.) %>% 
#           rowid_to_column() %>% 
#           rowid_to_column(var = 'global_id') %>% 
#           # rowid_to_column(var = 'internal_id') %>% # TODO get this squeeky clean
#           mutate(  id = paste(state, city, holc_id, holc_grade, rowid, sep = '_')
#                  , city_state = paste0(city, ', ', state)
#                  , area_holc_km2 = as.double(st_area(.) / 1e+6)) %>% 
#   select(id, global_id, state, city, holc_id, holc_grade, city_state, area_holc_km2));toc() # < 5 seconds

# *** OR ***

# NOTICE !!! as_Spatial was failing because 'FL_Jacksonville_B3_B_1404' is a linstring, not a polygon
# F FL but go 'Gators!
(holc <- st_read('working_data/holc_polys_saved/holc_plys_2022-12-08 20-13-17.gpkg', as_tibble = TRUE) |> 
  filter(st_is(geom, 'POLYGON')))



# # map holc polygons and MSA
# holc |> 
#   # too many polygons at once.. filter by a state
#   # filter(state == 'CA') |> 
#   filter(state == 'NY') |>
#   # filter(state == 'MA') |> 
#   mapview(zcol =   'holc_grade'
#                 , col.regions = holc_pal) +
#   mapview(msa_w_holc, alpha.regions = 0) #+ # clear polygon, black boarder
#   # mapview(ua)
```


## B MSAs
```{r}
msa_w_holc <- 
  st_read(paste0(getwd()
                 , '/working_data/MSA/msa_as_geopackage_2022-12-08 15-40-07.gpkg'))

# msa_w_holc |> mapview() 

```

### i erase holc from msa
```{r}

# msa_ungraded <- st_erase_3(msa_w_holc, holc)
# 
# # 2x check
# msa_ungraded
# msa_ungraded |> mapview()
# 
# # save out
# tic(); msa_ungraded |> st_write('working_data/MSA_donut/msa_ungraded.gpkg'); toc(); beepr::beep()

msa_ungraded <- st_read('working_data/MSA_donut/msa_ungraded.gpkg')

msa_ungraded |> mapview()


```


## C Urban Areas (skip and just read in)
```{r eval=FALSE, include=FALSE}

# read in from census
tic();(
  ua <- 
    get_acs(  geography = "urban area"
            , variable = c(ua_population = 'B01001_001') # population - just need some variable
            , year = 2019
            , geometry = TRUE
            , output = 'wide'
            ) %>%
    st_transform(crs = st_crs(msa_w_holc)) %>%
    mutate(ua_area_km2 = as.double(st_area(.) / 1e+6))); beep(); toc() #

# take a look
mapview(ua)



# find HOLC polygons that cross MSA lines, fix assignment

# intersect to find 'broken' polygons straddling across urban area lines
tic(); test_holc_ua_int <- st_par(  holc
                                  , st_intersection
                                  , n_cores = 10
                                  , y = ua); toc() # ~2 seconds w 10 cores

# how many cross-boundary holc polygons do we have.
holc |> nrow() - test_holc_ua_int |> nrow() # woohoo no stradlers. Success.


# do UAs play nicely with MSAs to?

# # intersect to find 'broken' polygons straddling across urban area lines
# tic(); test_ua_msa_int <- st_par(  ua
#                                  , st_intersection
#                                  , n_cores = 10
#                                  , y = msa_w_holc); toc() # ~1 seconds w 10 cores
# 
# # how many cross-boundary holc polygons do we have.
# ua |> nrow() - test_ua_msa_int |> nrow() # ugh, ok so that's not great..
# 
# # how are UA and MSA related though - imperfectly?
# test_ua_msa_int |>  st_collection_extract(., "POLYGON")
# test_ua_msa_int |> 
#   rownames_to_column() |> 
#   select(rowname, ua_GEOID = GEOID, ua_name = NAME, msa_GEOID, msa_name) |> 
#   st_drop_geometry() |> 
#   as_tibble() |> 
#   distinct(ua_GEOID, ua_name, msa_GEOID, msa_name) |> # sanity check
#   arrange(ua_name, msa_name) |> # cosmetic
#   write_csv('working_data/MSA_UA_lookup.csv')

# urban area ids we are actually using
(ua_ids <- 
  st_read('working_data/UA/UA_as_geopackage_2023-01-23 15-48-08.gpkg') |> 
  st_drop_geometry() |> 
  tidylog::select(ua_GEOID = GEOID) |> 
  pull(ua_GEOID))

(ua_msa_int <- read_csv('working_data/MSA_UA_lookup.csv') |> 
  filter(ua_GEOID %in% ua_ids))

ua_msa_int |> distinct(ua_name)
ua_msa_int |> distinct(msa_name)

# so who splits?
ua_msa_int |> distinct(ua_name, msa_name)
ua_msa_int |> 
  group_by(msa_name) |> add_count() |> arrange(desc(n), msa_name) |> tail()
  # count() |> 
  # arrange(desc(n)) #|> tail()

# double checks
ua_msa_int |> 
  tabyl(ua_name, msa_name) |> 
  tibble() |> 
  pivot_longer(-ua_name) |> 
  filter(value > 0)

# just use UA's with HOLC and see how they visually overlay
# extract ids
ua_ids_w_holc <- 
  test_holc_ua_int |> 
  st_drop_geometry() |> 
  select(ua_name = NAME) |> 
  distinct(ua_name)

# summary: HOLC polys fit perfectly within their UA's and MSA's. But UA's do not fit perfectly within their MSA's

# viz the relationship between MSA and UA
ua |> 
  filter(NAME %in% ua_ids_w_holc$ua_name) |> 
  mapview() +
  mapview(msa_w_holc, alpha.regions = 0) # clear polygon, black boarder


# save out ua's 
# create directory gbif points per biodiversity group spatially filtered to HOLC polygons
ifelse( !dir.exists(paste0(getwd(), '/working_data/UA'))
       , dir.create(paste0(getwd(), '/working_data/UA'))
       , FALSE)

# ua |> 
#   filter(NAME %in% ua_ids_w_holc$ua_name) |> 
#   st_write(paste0(getwd()
#                   , '/working_data/UA/UA_as_geopackage_'
#                   ,  gsub('[[:punct:]]', '-', Sys.time())
#                   , '.gpkg'))


rm(test_holc_ua_int, test_ua_msa_int)
```


### ii read in urban areas with HOLC (skip?)
```{r}
ua_with_holc <- st_read('working_data/UA/UA_as_geopackage_2023-01-23 15-48-08.gpkg')

# ua_with_holc |> mapview() +
#   holc |>
#   filter(state == 'NY' | state == 'PA' | state == 'MD' | state == 'NJ') |> # just for speed and ease
#   mapview(zcol =   'holc_grade'
#                 , col.regions = holc_pal)
```

### iii erase holc from ua
```{r}

# ua_ungraded <- st_erase_3(ua_with_holc, holc)
# 
# 
# ua_ungraded |> filter(st_is(geom, 'MULTIPOLYGON')) # none removed
# 
# 
# # ua_ungraded |> mapview()
# 
# 
# # save out ua donuts
# # create directory gbif points per biodiversity group spatially filtered to HOLC polygons
# ifelse( !dir.exists(paste0(getwd(), '/working_data/UA_donut'))
#        , dir.create(paste0(getwd(), '/working_data/UA_donut'))
#        , FALSE)
# 
# ua_ungraded |>
#   st_write(paste0(getwd()
#                   , '/working_data/UA_donut/UA_ungraded_'
#                   ,  gsub('[[:punct:]]', '-', Sys.time())
#                   , '.gpkg'))

ua_ungraded <- st_read('working_data/UA_donut/UA_ungraded_2023-01-23 16-05-42.gpkg')

ua_ungraded |>  mapview()

```


## End

# sand box
