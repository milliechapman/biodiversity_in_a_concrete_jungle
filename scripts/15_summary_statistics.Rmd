---
title: "15_summary_statistics"
author: "Dexter H. Locke, PhD"
date: "`r format(Sys.time())`"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


    
# 0 set up: load libraries, custom functions, set defaults
```{r}

# load libraries
# packages we'll be using
packs <- c(
    'tidyverse'  # a must have
  , 'tidylog'    # prints out what was done in dplyr and tidr
  # , 'gbifdb' # GBIF
  # , 'fst' # a faster table, makes outputs files much smaller, too.
  # , 'terra'
  # , 'KnowBR'    # creates biodiversity estimates like completeness.
  , 'tidycensus'      # Census access
  , 'sf'        # spatial support
  , 'mapview'   # webmaps
  , 'janitor'   # cleans things up, also pipe-friendly cross-tabulations
  , 'tictoc'    # times things
  , 'beepr'     # makes noises
  # , 'ggpubr'    # boxplots with significance testing.
  # , 'lme4'
  # , 'ggeffects' # nice predictions
  )


# check for all of the libraries, install if you don't have them
if (length(setdiff(packs, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packs, rownames(installed.packages())))  
}

# load them
vapply(packs, library, character.only = TRUE, logical(1), logical.return = TRUE, quietly = TRUE)



# custom function for "Not In"
`%nin%` <- Negate(`%in%`)


# redlining colors
holc_pal <- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              #, '#A9A9A9'
              ) # dark gray)

holc_pal_f<- c('#92BC6B' # green
              , '#92C7C9' # blue
              , '#E7DC6B' # yellow
              , '#E47D67' # red
              , '#A9A9A9'
              , '#000000')

# fixes mapview
mapviewOptions(fgb = FALSE)
```

# 1 read data
## A MSA / UA / States 
```{r}
# load('working_data/nested_data/nested_data_2023-10-13.RData')
# load('working_data/nested_data/nested_data_2024-02-19.RData') # contains area for computing expected richness per area
load('working_data/nested_data/nested_data_2024-02-20.RData')

# How many MSAs?
nested_data |> 
  drop_na() |> 
  unnest(data) |> 
  ungroup() |> 
  distinct(msa_GEOID) |> 
  nrow()

# How many UAs?
nested_data |> 
  drop_na() |> 
  unnest(data) |> 
  ungroup() |> 
  distinct(msa_GEOID) |> 
  full_join(
    read_csv('working_data/MSA_UA_lookup.csv') |> 
      mutate(msa_GEOID =as.character(msa_GEOID))
    ) |> distinct(ua_name)

# how many states?
sf::sf_use_s2(FALSE) # supresses error in some sf opperations, probably not needed?

states <- 
  st_read('working_data/holc_polys_saved/holc_plys_2022-12-08 20-13-17.gpkg') |> 
  distinct(state)

states |> nrow()


# How many HOLC polygons?
nested_data |> 
  drop_na() |> 
  unnest(data) |> 
  ungroup() |> 
  distinct(id) |> 
  nrow()

```



## B GBIF counts per MSA
```{r}

list.files('../biodiversity_in_a_concrete_jungle_data_too_big/gbif_by_MSA', recursive = TRUE)

(
  msa_counts_taxon <- 
  tibble(filename = list.files('../biodiversity_in_a_concrete_jungle_data_too_big/gbif_by_MSA'
                               , full.names = TRUE
                               , recursive = TRUE # for aves
                               , pattern = 'fst'
                               )
         , file_contents = map(filename, ~fst::read_fst(.))
         , n = map(file_contents, ~nrow(.))
         ) |> 
  select(filename, n) |> # save weight
  unnest(n) |> 
  mutate(taxon = str_remove(filename, '../biodiversity_in_a_concrete_jungle_data_too_big/gbif_by_MSA/gbif_') |> 
           str_remove('../biodiversity_in_a_concrete_jungle_data_too_big/gbif_by_MSA/aves/') |> 
           str_remove('_.*')) |> # '_.*' means everything after '_'
  group_by(taxon) |> 
  summarise(n = sum(n)) |> 
  arrange(taxon) |> 
  adorn_totals()
  )

msa_counts_taxon |> 
  adorn_percentages('col') |> 
  mutate(pct = 100*n) |> 
  tibble() |> 
  arrange(desc(pct))

```


## C what is the average completeness?
```{r}

mods_preds |>
  unnest(preds) |> 
  mutate(across(c(predicted, conf.low, conf.high), ~ifelse(dv == 'completeness', .x, exp(.x)))) |> 
  filter(dv == 'completeness') |>
  group_by() |> 
  summarise(mean_est_comp = mean(predicted))


mods_preds |>
  unnest(preds) |> 
  mutate(across(c(predicted, conf.low, conf.high), ~ifelse(dv == 'completeness', .x, exp(.x)))) |> 
  filter(dv == 'completeness') |>
  group_by(taxon, level) |> 
  summarise(mean_est_comp = mean(predicted))

```



